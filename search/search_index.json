{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"TorchSpy","text":"<p>A lightweight debug tool for saving and inspecting intermediate tensors during PyTorch model forward passes.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Non-intrusive debugging: Add <code>spy_save()</code> calls to your model without changing the forward logic</li> <li>Call tracing: Automatically record module execution order using forward hooks</li> <li>Context-aware saving: Use <code>DebugContext</code> to add prefixes and organize saved tensors</li> <li>Module path tracking: Automatically tracks module hierarchy paths for meaningful tensor names</li> <li>Thread-safe: Uses context variables for safe concurrent execution</li> <li>Flexible registration: Register modules by class type or name pattern</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install torchspy\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#saving-tensors","title":"Saving Tensors","text":"<pre><code>from torchspy.saver import TensorSaver\nfrom torchspy.context import DebugContext\nfrom torchspy.saver import spy_save\n\n# Setup\nsaver = TensorSaver(\"./debug_tensors\")\nsaver.register_modules(model, target_classes=(AttentionLayer,))\n\n# In your module's forward():\nspy_save(\"q\", q, self)\n\n# Run with context\nwith DebugContext(saver, prefix=\"step0\"):\n    output = model(inputs)\n</code></pre>"},{"location":"#tracing-module-calls","title":"Tracing Module Calls","text":"<pre><code>from torchspy import CallTracer\n\n# Setup tracer\ntracer = CallTracer(\"./debug_traces\")\ntracer.register_hooks(model, target_classes=(nn.Linear,))\n\n# Run forward pass - hooks record call order automatically\noutput = model(inputs)\n\n# Save trace to file\ntracer.save_trace(\"call_order.txt\")\n</code></pre> <p>See API Reference for detailed documentation.</p>"},{"location":"modules/","title":"API Reference","text":""},{"location":"modules/#tensor-saving","title":"Tensor Saving","text":""},{"location":"modules/#torchspy.saver.TensorSaver","title":"<code>torchspy.saver.TensorSaver</code>","text":"<p>               Bases: <code>BaseDebugger</code></p> <p>Utility to save intermediate tensors during PyTorch forward passes.</p> <p>This class registers module paths and provides infrastructure for saving tensors from within module forward methods via the spy_save() function.</p> <p>Attributes:</p> Name Type Description <code>output_dir</code> <code>Path</code> <p>Directory where tensors are saved.</p> <code>enabled</code> <code>bool</code> <p>Whether debugging is active.</p> <code>call_counts</code> <code>dict[str, int]</code> <p>Tracks call count per tensor name.</p> <code>module_paths</code> <code>dict[int, str]</code> <p>Maps module id to its path string.</p> Example <p>from torchspy import TensorSaver, DebugContext, spy_save</p> Source code in <code>src/torchspy/saver.py</code> <pre><code>class TensorSaver(BaseDebugger):\n    \"\"\"Utility to save intermediate tensors during PyTorch forward passes.\n\n    This class registers module paths and provides infrastructure for saving\n    tensors from within module forward methods via the spy_save() function.\n\n    Attributes:\n        output_dir (Path): Directory where tensors are saved.\n        enabled (bool): Whether debugging is active.\n        call_counts (dict[str, int]): Tracks call count per tensor name.\n        module_paths (dict[int, str]): Maps module id to its path string.\n\n    Example:\n        &gt;&gt;&gt; from torchspy import TensorSaver, DebugContext, spy_save\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Setup saver\n        &gt;&gt;&gt; saver = TensorSaver(\"./debug_tensors\")\n        &gt;&gt;&gt; saver.register_modules(model, target_classes=(AttentionLayer,))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Run with debug context\n        &gt;&gt;&gt; with DebugContext(saver, prefix=\"step0\"):\n        ...     output = model(inputs)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Inside your module's forward(), call spy_save():\n        &gt;&gt;&gt; # spy_save(\"q\", q, self)  # saves as {prefix}.{module_path}.q.call{n}.pt\n\n    \"\"\"\n\n    def __init__(self, output_dir: str | Path, enabled: bool = True) -&gt; None:\n        \"\"\"Initialize the tensor saver.\n\n        Args:\n            output_dir (str | Path): Directory to save tensor files.\n            enabled (bool): Whether saving is enabled. Defaults to True.\n\n        \"\"\"\n        super().__init__(output_dir, enabled)\n        self.call_counts: dict[str, int] = defaultdict(int)\n\n    def register_modules(\n        self,\n        model: nn.Module,\n        target_classes: tuple[Type[nn.Module], ...] = (nn.Module,),\n        target_names: list[str] | None = None,\n        exclude_names: list[str] | None = None,\n    ) -&gt; None:\n        \"\"\"Register module paths for target modules.\n\n        This populates the module_paths mapping so that spy_save() can\n        look up the module's path in the model hierarchy.\n\n        Args:\n            model (nn.Module): The root model to inspect.\n            target_classes (tuple[Type[nn.Module], ...]): Register modules\n                that are instances of these classes.\n            target_names (list[str] | None): Register modules whose path\n                contains any of these substrings.\n            exclude_names (list[str] | None): Exclude modules whose path\n                contains any of these substrings.\n\n        \"\"\"\n        for name, module in model.named_modules():\n            module_path = name or \"root\"\n            if self._should_register_module(\n                module, module_path, target_classes, target_names, exclude_names\n            ):\n                self.module_paths[id(module)] = module_path\n                logger.info(\"Registered module path: %s\", module_path)\n\n    def save(\n        self,\n        name: str,\n        tensor: Tensor,\n        call_idx: int | None = None,\n        norm_only: bool = False,\n    ) -&gt; None:\n        \"\"\"Save a tensor to disk.\n\n        Args:\n            name (str): The tensor name (will be used in filename).\n            tensor (Tensor): The tensor to save.\n            call_idx (int | None): Call index. If None, auto-increments\n                based on name.\n            norm_only (bool): If True, save only the L2 norm of the tensor\n                (flattened per batch). Defaults to False.\n\n        \"\"\"\n        if not self.enabled:\n            return\n\n        if call_idx is None:\n            call_idx = self.call_counts[name]\n            self.call_counts[name] += 1\n\n        filename = f\"{name}.call{call_idx}.pt\"\n        path = self.output_dir / filename\n        if norm_only:\n            tensor = tensor.view(tensor.size(0), -1)\n            tensor = LA.norm(tensor, dim=-1)\n        torch.save(tensor.detach().cpu(), path)\n        logger.debug(\"Saved tensor: %s\", path)\n\n    def reset_counts(self) -&gt; None:\n        \"\"\"Reset all call counters.\n\n        Call this between batches if you want per-batch indexing.\n\n        \"\"\"\n        self.call_counts.clear()\n</code></pre>"},{"location":"modules/#torchspy.saver.TensorSaver--setup-saver","title":"Setup saver","text":"<p>saver = TensorSaver(\"./debug_tensors\") saver.register_modules(model, target_classes=(AttentionLayer,))</p>"},{"location":"modules/#torchspy.saver.TensorSaver--run-with-debug-context","title":"Run with debug context","text":"<p>with DebugContext(saver, prefix=\"step0\"): ...     output = model(inputs)</p>"},{"location":"modules/#torchspy.saver.TensorSaver--inside-your-modules-forward-call-spy_save","title":"Inside your module's forward(), call spy_save():","text":""},{"location":"modules/#torchspy.saver.TensorSaver--spy_saveq-q-self-saves-as-prefixmodule_pathqcallnpt","title":"spy_save(\"q\", q, self)  # saves as {prefix}.{module_path}.q.call{n}.pt","text":""},{"location":"modules/#torchspy.saver.TensorSaver.__init__","title":"<code>__init__(output_dir, enabled=True)</code>","text":"<p>Initialize the tensor saver.</p> <p>Parameters:</p> Name Type Description Default <code>output_dir</code> <code>str | Path</code> <p>Directory to save tensor files.</p> required <code>enabled</code> <code>bool</code> <p>Whether saving is enabled. Defaults to True.</p> <code>True</code> Source code in <code>src/torchspy/saver.py</code> <pre><code>def __init__(self, output_dir: str | Path, enabled: bool = True) -&gt; None:\n    \"\"\"Initialize the tensor saver.\n\n    Args:\n        output_dir (str | Path): Directory to save tensor files.\n        enabled (bool): Whether saving is enabled. Defaults to True.\n\n    \"\"\"\n    super().__init__(output_dir, enabled)\n    self.call_counts: dict[str, int] = defaultdict(int)\n</code></pre>"},{"location":"modules/#torchspy.saver.TensorSaver.register_modules","title":"<code>register_modules(model, target_classes=(nn.Module,), target_names=None, exclude_names=None)</code>","text":"<p>Register module paths for target modules.</p> <p>This populates the module_paths mapping so that spy_save() can look up the module's path in the model hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The root model to inspect.</p> required <code>target_classes</code> <code>tuple[Type[Module], ...]</code> <p>Register modules that are instances of these classes.</p> <code>(Module,)</code> <code>target_names</code> <code>list[str] | None</code> <p>Register modules whose path contains any of these substrings.</p> <code>None</code> <code>exclude_names</code> <code>list[str] | None</code> <p>Exclude modules whose path contains any of these substrings.</p> <code>None</code> Source code in <code>src/torchspy/saver.py</code> <pre><code>def register_modules(\n    self,\n    model: nn.Module,\n    target_classes: tuple[Type[nn.Module], ...] = (nn.Module,),\n    target_names: list[str] | None = None,\n    exclude_names: list[str] | None = None,\n) -&gt; None:\n    \"\"\"Register module paths for target modules.\n\n    This populates the module_paths mapping so that spy_save() can\n    look up the module's path in the model hierarchy.\n\n    Args:\n        model (nn.Module): The root model to inspect.\n        target_classes (tuple[Type[nn.Module], ...]): Register modules\n            that are instances of these classes.\n        target_names (list[str] | None): Register modules whose path\n            contains any of these substrings.\n        exclude_names (list[str] | None): Exclude modules whose path\n            contains any of these substrings.\n\n    \"\"\"\n    for name, module in model.named_modules():\n        module_path = name or \"root\"\n        if self._should_register_module(\n            module, module_path, target_classes, target_names, exclude_names\n        ):\n            self.module_paths[id(module)] = module_path\n            logger.info(\"Registered module path: %s\", module_path)\n</code></pre>"},{"location":"modules/#torchspy.saver.TensorSaver.save","title":"<code>save(name, tensor, call_idx=None, norm_only=False)</code>","text":"<p>Save a tensor to disk.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The tensor name (will be used in filename).</p> required <code>tensor</code> <code>Tensor</code> <p>The tensor to save.</p> required <code>call_idx</code> <code>int | None</code> <p>Call index. If None, auto-increments based on name.</p> <code>None</code> <code>norm_only</code> <code>bool</code> <p>If True, save only the L2 norm of the tensor (flattened per batch). Defaults to False.</p> <code>False</code> Source code in <code>src/torchspy/saver.py</code> <pre><code>def save(\n    self,\n    name: str,\n    tensor: Tensor,\n    call_idx: int | None = None,\n    norm_only: bool = False,\n) -&gt; None:\n    \"\"\"Save a tensor to disk.\n\n    Args:\n        name (str): The tensor name (will be used in filename).\n        tensor (Tensor): The tensor to save.\n        call_idx (int | None): Call index. If None, auto-increments\n            based on name.\n        norm_only (bool): If True, save only the L2 norm of the tensor\n            (flattened per batch). Defaults to False.\n\n    \"\"\"\n    if not self.enabled:\n        return\n\n    if call_idx is None:\n        call_idx = self.call_counts[name]\n        self.call_counts[name] += 1\n\n    filename = f\"{name}.call{call_idx}.pt\"\n    path = self.output_dir / filename\n    if norm_only:\n        tensor = tensor.view(tensor.size(0), -1)\n        tensor = LA.norm(tensor, dim=-1)\n    torch.save(tensor.detach().cpu(), path)\n    logger.debug(\"Saved tensor: %s\", path)\n</code></pre>"},{"location":"modules/#torchspy.saver.TensorSaver.reset_counts","title":"<code>reset_counts()</code>","text":"<p>Reset all call counters.</p> <p>Call this between batches if you want per-batch indexing.</p> Source code in <code>src/torchspy/saver.py</code> <pre><code>def reset_counts(self) -&gt; None:\n    \"\"\"Reset all call counters.\n\n    Call this between batches if you want per-batch indexing.\n\n    \"\"\"\n    self.call_counts.clear()\n</code></pre>"},{"location":"modules/#torchspy.context.DebugContext","title":"<code>torchspy.context.DebugContext</code>","text":"<p>Context manager for scoped tensor debugging.</p> <p>Use this to add a prefix to saved tensors and enable spy_save() calls within module forward methods.</p> <p>Attributes:</p> Name Type Description <code>saver</code> <code>TensorSaver</code> <p>The saver instance to use.</p> <code>prefix</code> <code>str</code> <p>Prefix added to all tensor names in this context.</p> <code>module_path_override</code> <code>str | None</code> <p>Override module path for spy_save().</p> Example <p>from torchspy import TensorSaver, DebugContext</p> <p>saver = TensorSaver(\"./debug_tensors\") with DebugContext(saver, prefix=\"batch0_step0\"): ...     output = model(inputs) ...     # Inside forward: spy_save(\"q\", q, self) ...     # Saves as: batch0_step0.{module_path}.q.call0.pt</p> Source code in <code>src/torchspy/context.py</code> <pre><code>class DebugContext:\n    \"\"\"Context manager for scoped tensor debugging.\n\n    Use this to add a prefix to saved tensors and enable spy_save() calls\n    within module forward methods.\n\n    Attributes:\n        saver (TensorSaver): The saver instance to use.\n        prefix (str): Prefix added to all tensor names in this context.\n        module_path_override (str | None): Override module path for spy_save().\n\n    Example:\n        &gt;&gt;&gt; from torchspy import TensorSaver, DebugContext\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; saver = TensorSaver(\"./debug_tensors\")\n        &gt;&gt;&gt; with DebugContext(saver, prefix=\"batch0_step0\"):\n        ...     output = model(inputs)\n        ...     # Inside forward: spy_save(\"q\", q, self)\n        ...     # Saves as: batch0_step0.{module_path}.q.call0.pt\n\n    \"\"\"\n\n    def __init__(\n        self,\n        saver: \"TensorSaver\",\n        prefix: str = \"\",\n        module_path_override: str | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the debug context.\n\n        Args:\n            saver (TensorSaver): The saver instance.\n            prefix (str): Prefix for tensor names. Defaults to \"\".\n            module_path_override (str | None): Override the module path.\n                Useful when calling spy_save() from helper functions.\n\n        \"\"\"\n        self.saver = saver\n        self.prefix = prefix\n        self.module_path_override = module_path_override\n        self._token: contextvars.Token | None = None\n\n    # Backward compatibility alias\n    @property\n    def debugger(self) -&gt; \"TensorSaver\":\n        \"\"\"Backward compatibility alias for saver.\"\"\"\n        return self.saver\n\n    def __enter__(self) -&gt; \"DebugContext\":\n        \"\"\"Enter the debug context.\"\"\"\n        self._token = _debug_context.set(self)\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb) -&gt; None:\n        \"\"\"Exit the debug context.\"\"\"\n        if self._token is not None:\n            _debug_context.reset(self._token)\n\n    def _save(self, name: str, tensor: Tensor, module: nn.Module | None = None) -&gt; None:\n        \"\"\"Save a tensor with context-aware naming.\n\n        Args:\n            name (str): The tensor variable name (e.g., \"q\", \"attn_mask\").\n            tensor (Tensor): The tensor to save.\n            module (nn.Module | None): The module saving this tensor.\n                Used to look up the module path.\n\n        \"\"\"\n        if self.module_path_override is not None:\n            module_path = self.module_path_override\n        elif module is not None:\n            module_path = self.saver.get_module_path(module)\n        else:\n            module_path = \"manual\"\n\n        if module_path == \"unknown\":\n            logger.warning(\"Module path unknown for tensor '%s'. Skipping save.\", name)\n            return\n\n        full_name = (\n            f\"{self.prefix}.{module_path}.{name}\"\n            if self.prefix\n            else f\"{module_path}.{name}\"\n        )\n        self.saver.save(full_name, tensor)\n</code></pre>"},{"location":"modules/#torchspy.context.DebugContext.__init__","title":"<code>__init__(saver, prefix='', module_path_override=None)</code>","text":"<p>Initialize the debug context.</p> <p>Parameters:</p> Name Type Description Default <code>saver</code> <code>TensorSaver</code> <p>The saver instance.</p> required <code>prefix</code> <code>str</code> <p>Prefix for tensor names. Defaults to \"\".</p> <code>''</code> <code>module_path_override</code> <code>str | None</code> <p>Override the module path. Useful when calling spy_save() from helper functions.</p> <code>None</code> Source code in <code>src/torchspy/context.py</code> <pre><code>def __init__(\n    self,\n    saver: \"TensorSaver\",\n    prefix: str = \"\",\n    module_path_override: str | None = None,\n) -&gt; None:\n    \"\"\"Initialize the debug context.\n\n    Args:\n        saver (TensorSaver): The saver instance.\n        prefix (str): Prefix for tensor names. Defaults to \"\".\n        module_path_override (str | None): Override the module path.\n            Useful when calling spy_save() from helper functions.\n\n    \"\"\"\n    self.saver = saver\n    self.prefix = prefix\n    self.module_path_override = module_path_override\n    self._token: contextvars.Token | None = None\n</code></pre>"},{"location":"modules/#torchspy.context.DebugContext.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter the debug context.</p> Source code in <code>src/torchspy/context.py</code> <pre><code>def __enter__(self) -&gt; \"DebugContext\":\n    \"\"\"Enter the debug context.\"\"\"\n    self._token = _debug_context.set(self)\n    return self\n</code></pre>"},{"location":"modules/#torchspy.context.DebugContext.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Exit the debug context.</p> Source code in <code>src/torchspy/context.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb) -&gt; None:\n    \"\"\"Exit the debug context.\"\"\"\n    if self._token is not None:\n        _debug_context.reset(self._token)\n</code></pre>"},{"location":"modules/#torchspy.saver.spy_save","title":"<code>torchspy.saver.spy_save(name, tensor, module=None)</code>","text":"<p>Save a tensor if a debug context is active.</p> <p>This is a convenience function to call from within module forward methods. If no debug context is active, this function does nothing (no-op).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The tensor variable name (e.g., \"q\", \"k\", \"attn_mask\").</p> required <code>tensor</code> <code>Tensor</code> <p>The tensor to save.</p> required <code>module</code> <code>Module | None</code> <p>The module instance (self). Used to determine the module path. Pass  from within a module's forward().</p> <code>None</code> Example <p>class MyModule(nn.Module): ...     def forward(self, x): ...         q = self.proj_q(x) ...         spy_save(\"q\", q, self) ...         return q</p> Source code in <code>src/torchspy/saver.py</code> <pre><code>def spy_save(name: str, tensor: Tensor, module: nn.Module | None = None) -&gt; None:\n    \"\"\"Save a tensor if a debug context is active.\n\n    This is a convenience function to call from within module forward methods.\n    If no debug context is active, this function does nothing (no-op).\n\n    Args:\n        name (str): The tensor variable name (e.g., \"q\", \"k\", \"attn_mask\").\n        tensor (Tensor): The tensor to save.\n        module (nn.Module | None): The module instance (self). Used to determine\n            the module path. Pass  from within a module's forward().\n\n    Example:\n        &gt;&gt;&gt; class MyModule(nn.Module):\n        ...     def forward(self, x):\n        ...         q = self.proj_q(x)\n        ...         spy_save(\"q\", q, self)\n        ...         return q\n\n    \"\"\"\n    ctx = get_debug_context()\n    if ctx is not None:\n        ctx._save(name, tensor, module)\n</code></pre>"},{"location":"modules/#torchspy.context.get_debug_context","title":"<code>torchspy.context.get_debug_context()</code>","text":"<p>Get the current debug context.</p> <p>Returns:</p> Type Description <code>DebugContext | None</code> <p>DebugContext | None: The active context, or None if no context is active.</p> Source code in <code>src/torchspy/context.py</code> <pre><code>def get_debug_context() -&gt; DebugContext | None:\n    \"\"\"Get the current debug context.\n\n    Returns:\n        DebugContext | None: The active context, or None if no context is active.\n\n    \"\"\"\n    return _debug_context.get()\n</code></pre>"},{"location":"modules/#call-tracing","title":"Call Tracing","text":""},{"location":"modules/#torchspy.tracer.CallTracer","title":"<code>torchspy.tracer.CallTracer</code>","text":"<p>               Bases: <code>BaseDebugger</code></p> <p>Traces the execution order of PyTorch modules using forward hooks.</p> <p>This class registers forward hooks on target modules to automatically record their call order without requiring any modifications to the module code.</p> <p>Attributes:</p> Name Type Description <code>output_dir</code> <code>Path</code> <p>Directory where trace files are saved.</p> <code>enabled</code> <code>bool</code> <p>Whether tracing is active.</p> <code>call_trace</code> <code>list[str]</code> <p>List of module paths in call order.</p> <code>module_paths</code> <code>dict[int, str]</code> <p>Maps module id to its path string.</p> <code>hooks</code> <code>list</code> <p>List of registered hook handles for cleanup.</p> Example <p>from torchspy import CallTracer</p> <p>tracer = CallTracer(\"./debug_traces\") tracer.register_hooks(model, target_classes=(nn.Linear, nn.MultiheadAttention))</p> Source code in <code>src/torchspy/tracer.py</code> <pre><code>class CallTracer(BaseDebugger):\n    \"\"\"Traces the execution order of PyTorch modules using forward hooks.\n\n    This class registers forward hooks on target modules to automatically\n    record their call order without requiring any modifications to the\n    module code.\n\n    Attributes:\n        output_dir (Path): Directory where trace files are saved.\n        enabled (bool): Whether tracing is active.\n        call_trace (list[str]): List of module paths in call order.\n        module_paths (dict[int, str]): Maps module id to its path string.\n        hooks (list): List of registered hook handles for cleanup.\n\n    Example:\n        &gt;&gt;&gt; from torchspy import CallTracer\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; tracer = CallTracer(\"./debug_traces\")\n        &gt;&gt;&gt; tracer.register_hooks(model, target_classes=(nn.Linear, nn.MultiheadAttention))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Run forward pass - hooks automatically record call order\n        &gt;&gt;&gt; output = model(inputs)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Save the trace\n        &gt;&gt;&gt; tracer.save_trace(\"forward_pass.txt\")\n        &gt;&gt;&gt; # Or get the trace as a list\n        &gt;&gt;&gt; print(tracer.call_trace)\n\n    \"\"\"\n\n    def __init__(self, output_dir: str | Path, enabled: bool = True) -&gt; None:\n        \"\"\"Initialize the call tracer.\n\n        Args:\n            output_dir (str | Path): Directory to save trace files.\n            enabled (bool): Whether tracing is enabled. Defaults to True.\n\n        \"\"\"\n        super().__init__(output_dir, enabled)\n        self.call_trace: list[str] = []\n        self.hooks: list[Any] = []\n\n    def register_hooks(\n        self,\n        model: nn.Module,\n        target_classes: tuple[Type[nn.Module], ...] = (nn.Module,),\n        target_names: list[str] | None = None,\n        exclude_names: list[str] | None = None,\n    ) -&gt; None:\n        \"\"\"Register forward hooks on target modules.\n\n        This method walks through the model hierarchy and registers forward\n        hooks on modules that match the specified criteria.\n\n        Args:\n            model (nn.Module): The root model to inspect.\n            target_classes (tuple[Type[nn.Module], ...]): Register hooks on\n                modules that are instances of these classes. Defaults to (nn.Module,).\n            target_names (list[str] | None): Register hooks on modules whose\n                path contains any of these substrings.\n            exclude_names (list[str] | None): Exclude modules whose path\n                contains any of these substrings.\n\n        \"\"\"\n        for name, module in model.named_modules():\n            module_path = name or \"root\"\n            if self._should_register_module(\n                module, module_path, target_classes, target_names, exclude_names\n            ):\n                self.module_paths[id(module)] = module_path\n                hook = module.register_forward_hook(self._create_hook(module_path))\n                self.hooks.append(hook)\n                logger.info(\"Registered hook on: %s\", module_path)\n\n    def _create_hook(self, module_path: str) -&gt; Callable:\n        \"\"\"Create a forward hook that records the module path.\n\n        Args:\n            module_path (str): The path of the module in the model hierarchy.\n\n        Returns:\n            Callable: A hook function that records the module call.\n\n        \"\"\"\n\n        def hook(module: nn.Module, input: Any, output: Any) -&gt; None:  # noqa: A002\n            if self.enabled:\n                self.call_trace.append(module_path)\n\n        return hook\n\n    def save_trace(self, filename: str = \"call_trace.txt\") -&gt; Path:\n        \"\"\"Save the call trace to a text file.\n\n        Args:\n            filename (str): Name of the output file. Defaults to \"call_trace.txt\".\n\n        Returns:\n            Path: Path to the saved trace file.\n\n        \"\"\"\n        path = self.output_dir / filename\n        with open(path, \"w\") as f:\n            f.write(\"\\n\".join(self.call_trace))\n        logger.info(\"Saved call trace to: %s (%d calls)\", path, len(self.call_trace))\n        return path\n\n    def get_trace(self) -&gt; list[str]:\n        \"\"\"Get the current call trace.\n\n        Returns:\n            list[str]: List of module paths in call order.\n\n        \"\"\"\n        return self.call_trace.copy()\n\n    def reset_trace(self) -&gt; None:\n        \"\"\"Clear the recorded call trace.\"\"\"\n        self.call_trace.clear()\n\n    def remove_hooks(self) -&gt; None:\n        \"\"\"Remove all registered forward hooks.\"\"\"\n        for hook in self.hooks:\n            hook.remove()\n        self.hooks.clear()\n        logger.info(\"Removed all hooks\")\n\n    def __enter__(self) -&gt; \"CallTracer\":\n        \"\"\"Enter context - enable tracing.\"\"\"\n        self.enabled = True\n        self.reset_trace()\n        return self\n\n    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -&gt; None:\n        \"\"\"Exit context - optionally save trace.\"\"\"\n        pass\n\n    def __del__(self) -&gt; None:\n        \"\"\"Clean up hooks on deletion.\"\"\"\n        self.remove_hooks()\n</code></pre>"},{"location":"modules/#torchspy.tracer.CallTracer--run-forward-pass-hooks-automatically-record-call-order","title":"Run forward pass - hooks automatically record call order","text":"<p>output = model(inputs)</p>"},{"location":"modules/#torchspy.tracer.CallTracer--save-the-trace","title":"Save the trace","text":"<p>tracer.save_trace(\"forward_pass.txt\")</p>"},{"location":"modules/#torchspy.tracer.CallTracer--or-get-the-trace-as-a-list","title":"Or get the trace as a list","text":"<p>print(tracer.call_trace)</p>"},{"location":"modules/#torchspy.tracer.CallTracer.__init__","title":"<code>__init__(output_dir, enabled=True)</code>","text":"<p>Initialize the call tracer.</p> <p>Parameters:</p> Name Type Description Default <code>output_dir</code> <code>str | Path</code> <p>Directory to save trace files.</p> required <code>enabled</code> <code>bool</code> <p>Whether tracing is enabled. Defaults to True.</p> <code>True</code> Source code in <code>src/torchspy/tracer.py</code> <pre><code>def __init__(self, output_dir: str | Path, enabled: bool = True) -&gt; None:\n    \"\"\"Initialize the call tracer.\n\n    Args:\n        output_dir (str | Path): Directory to save trace files.\n        enabled (bool): Whether tracing is enabled. Defaults to True.\n\n    \"\"\"\n    super().__init__(output_dir, enabled)\n    self.call_trace: list[str] = []\n    self.hooks: list[Any] = []\n</code></pre>"},{"location":"modules/#torchspy.tracer.CallTracer.register_hooks","title":"<code>register_hooks(model, target_classes=(nn.Module,), target_names=None, exclude_names=None)</code>","text":"<p>Register forward hooks on target modules.</p> <p>This method walks through the model hierarchy and registers forward hooks on modules that match the specified criteria.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The root model to inspect.</p> required <code>target_classes</code> <code>tuple[Type[Module], ...]</code> <p>Register hooks on modules that are instances of these classes. Defaults to (nn.Module,).</p> <code>(Module,)</code> <code>target_names</code> <code>list[str] | None</code> <p>Register hooks on modules whose path contains any of these substrings.</p> <code>None</code> <code>exclude_names</code> <code>list[str] | None</code> <p>Exclude modules whose path contains any of these substrings.</p> <code>None</code> Source code in <code>src/torchspy/tracer.py</code> <pre><code>def register_hooks(\n    self,\n    model: nn.Module,\n    target_classes: tuple[Type[nn.Module], ...] = (nn.Module,),\n    target_names: list[str] | None = None,\n    exclude_names: list[str] | None = None,\n) -&gt; None:\n    \"\"\"Register forward hooks on target modules.\n\n    This method walks through the model hierarchy and registers forward\n    hooks on modules that match the specified criteria.\n\n    Args:\n        model (nn.Module): The root model to inspect.\n        target_classes (tuple[Type[nn.Module], ...]): Register hooks on\n            modules that are instances of these classes. Defaults to (nn.Module,).\n        target_names (list[str] | None): Register hooks on modules whose\n            path contains any of these substrings.\n        exclude_names (list[str] | None): Exclude modules whose path\n            contains any of these substrings.\n\n    \"\"\"\n    for name, module in model.named_modules():\n        module_path = name or \"root\"\n        if self._should_register_module(\n            module, module_path, target_classes, target_names, exclude_names\n        ):\n            self.module_paths[id(module)] = module_path\n            hook = module.register_forward_hook(self._create_hook(module_path))\n            self.hooks.append(hook)\n            logger.info(\"Registered hook on: %s\", module_path)\n</code></pre>"},{"location":"modules/#torchspy.tracer.CallTracer.save_trace","title":"<code>save_trace(filename='call_trace.txt')</code>","text":"<p>Save the call trace to a text file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Name of the output file. Defaults to \"call_trace.txt\".</p> <code>'call_trace.txt'</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Path to the saved trace file.</p> Source code in <code>src/torchspy/tracer.py</code> <pre><code>def save_trace(self, filename: str = \"call_trace.txt\") -&gt; Path:\n    \"\"\"Save the call trace to a text file.\n\n    Args:\n        filename (str): Name of the output file. Defaults to \"call_trace.txt\".\n\n    Returns:\n        Path: Path to the saved trace file.\n\n    \"\"\"\n    path = self.output_dir / filename\n    with open(path, \"w\") as f:\n        f.write(\"\\n\".join(self.call_trace))\n    logger.info(\"Saved call trace to: %s (%d calls)\", path, len(self.call_trace))\n    return path\n</code></pre>"},{"location":"modules/#torchspy.tracer.CallTracer.get_trace","title":"<code>get_trace()</code>","text":"<p>Get the current call trace.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: List of module paths in call order.</p> Source code in <code>src/torchspy/tracer.py</code> <pre><code>def get_trace(self) -&gt; list[str]:\n    \"\"\"Get the current call trace.\n\n    Returns:\n        list[str]: List of module paths in call order.\n\n    \"\"\"\n    return self.call_trace.copy()\n</code></pre>"},{"location":"modules/#torchspy.tracer.CallTracer.reset_trace","title":"<code>reset_trace()</code>","text":"<p>Clear the recorded call trace.</p> Source code in <code>src/torchspy/tracer.py</code> <pre><code>def reset_trace(self) -&gt; None:\n    \"\"\"Clear the recorded call trace.\"\"\"\n    self.call_trace.clear()\n</code></pre>"},{"location":"modules/#torchspy.tracer.CallTracer.remove_hooks","title":"<code>remove_hooks()</code>","text":"<p>Remove all registered forward hooks.</p> Source code in <code>src/torchspy/tracer.py</code> <pre><code>def remove_hooks(self) -&gt; None:\n    \"\"\"Remove all registered forward hooks.\"\"\"\n    for hook in self.hooks:\n        hook.remove()\n    self.hooks.clear()\n    logger.info(\"Removed all hooks\")\n</code></pre>"},{"location":"modules/#base-class","title":"Base Class","text":""},{"location":"modules/#torchspy._base.BaseDebugger","title":"<code>torchspy._base.BaseDebugger</code>","text":"<p>Base class for tensor debugging utilities.</p> <p>Provides common functionality for directory management and module registration that is shared between TensorSaver and CallTracer.</p> <p>Attributes:</p> Name Type Description <code>output_dir</code> <code>Path</code> <p>Directory where output files are saved.</p> <code>enabled</code> <code>bool</code> <p>Whether the debugger is active.</p> <code>module_paths</code> <code>dict[int, str]</code> <p>Maps module id to its path string.</p> Source code in <code>src/torchspy/_base.py</code> <pre><code>class BaseDebugger:\n    \"\"\"Base class for tensor debugging utilities.\n\n    Provides common functionality for directory management and module\n    registration that is shared between TensorSaver and CallTracer.\n\n    Attributes:\n        output_dir (Path): Directory where output files are saved.\n        enabled (bool): Whether the debugger is active.\n        module_paths (dict[int, str]): Maps module id to its path string.\n\n    \"\"\"\n\n    def __init__(self, output_dir: str | Path, enabled: bool = True) -&gt; None:\n        \"\"\"Initialize the base debugger.\n\n        Args:\n            output_dir (str | Path): Directory to save output files.\n            enabled (bool): Whether debugging is enabled. Defaults to True.\n\n        \"\"\"\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        self.enabled = enabled\n        self.module_paths: dict[int, str] = {}\n\n    def _should_register_module(\n        self,\n        module: nn.Module,\n        module_path: str,\n        target_classes: tuple[Type[nn.Module], ...],\n        target_names: list[str] | None,\n        exclude_names: list[str] | None,\n    ) -&gt; bool:\n        \"\"\"Determine if a module should be registered.\n\n        Args:\n            module (nn.Module): The module to check.\n            module_path (str): The module's path in the model hierarchy.\n            target_classes (tuple[Type[nn.Module], ...]): Register if instance of these.\n            target_names (list[str] | None): Register if path contains any of these.\n            exclude_names (list[str] | None): Exclude if path contains any of these.\n\n        Returns:\n            bool: True if the module should be registered.\n\n        \"\"\"\n\n        if not isinstance(module, target_classes):\n            return False\n\n        if target_names is not None and not any(t in module_path for t in target_names):\n            return False\n\n        if exclude_names is not None and any(t in module_path for t in exclude_names):\n            return False\n\n        return True\n\n    def get_module_path(self, module: nn.Module) -&gt; str:\n        \"\"\"Get the registered path for a module.\n\n        Args:\n            module (nn.Module): The module to look up.\n\n        Returns:\n            str: The module's path, or \"unknown\" if not registered.\n\n        \"\"\"\n        return self.module_paths.get(id(module), \"unknown\")\n</code></pre>"},{"location":"modules/#torchspy._base.BaseDebugger.__init__","title":"<code>__init__(output_dir, enabled=True)</code>","text":"<p>Initialize the base debugger.</p> <p>Parameters:</p> Name Type Description Default <code>output_dir</code> <code>str | Path</code> <p>Directory to save output files.</p> required <code>enabled</code> <code>bool</code> <p>Whether debugging is enabled. Defaults to True.</p> <code>True</code> Source code in <code>src/torchspy/_base.py</code> <pre><code>def __init__(self, output_dir: str | Path, enabled: bool = True) -&gt; None:\n    \"\"\"Initialize the base debugger.\n\n    Args:\n        output_dir (str | Path): Directory to save output files.\n        enabled (bool): Whether debugging is enabled. Defaults to True.\n\n    \"\"\"\n    self.output_dir = Path(output_dir)\n    self.output_dir.mkdir(parents=True, exist_ok=True)\n    self.enabled = enabled\n    self.module_paths: dict[int, str] = {}\n</code></pre>"},{"location":"modules/#torchspy._base.BaseDebugger.get_module_path","title":"<code>get_module_path(module)</code>","text":"<p>Get the registered path for a module.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The module to look up.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The module's path, or \"unknown\" if not registered.</p> Source code in <code>src/torchspy/_base.py</code> <pre><code>def get_module_path(self, module: nn.Module) -&gt; str:\n    \"\"\"Get the registered path for a module.\n\n    Args:\n        module (nn.Module): The module to look up.\n\n    Returns:\n        str: The module's path, or \"unknown\" if not registered.\n\n    \"\"\"\n    return self.module_paths.get(id(module), \"unknown\")\n</code></pre>"}]}